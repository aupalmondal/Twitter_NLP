{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ecaadb",
   "metadata": {},
   "source": [
    "Implementation of RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9850011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\am87383\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ecbbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7accf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "train_df = pd.read_csv(\"train_nlp.csv\")\n",
    "test_df = pd.read_csv(\"test_nlp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b08ebfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data num = 7613\n",
      "Num of contained-keyword sentence = 5973\n",
      "Num of nan keyword = 61\n",
      "The ratio of keyword in sentence = 0.790916313559322\n"
     ]
    }
   ],
   "source": [
    "keywords = train_df.keyword.values\n",
    "texts = train_df.text.values\n",
    "contained_keyword_num = 0\n",
    "nan_num = 0\n",
    "for keyword,text in zip(keywords,texts):\n",
    "    if isinstance(keyword, str):\n",
    "        if keyword.lower() in text.lower():\n",
    "            contained_keyword_num += 1\n",
    "    else:\n",
    "        nan_num += 1\n",
    "print(f'Total data num = {keywords.shape[0]}\\n'\n",
    "      f'Num of contained-keyword sentence = {contained_keyword_num}\\n'\n",
    "      f'Num of nan keyword = {nan_num}\\n'\n",
    "      f'The ratio of keyword in sentence = {contained_keyword_num / (keywords.shape[0] - nan_num)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01255793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05a8fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d30859d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### training set ####\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>7128</td>\n",
       "      <td>military</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Courageous and honest analysis of need to use ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>4688</td>\n",
       "      <td>engulfed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@ZachZaidman @670TheScore wld b a shame if tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4907</th>\n",
       "      <td>6984</td>\n",
       "      <td>massacre</td>\n",
       "      <td>Cottonwood Arizona</td>\n",
       "      <td>Tell @BarackObama to rescind medals of 'honor'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>4103</td>\n",
       "      <td>drought</td>\n",
       "      <td>Spokane, WA</td>\n",
       "      <td>Worried about how the CA drought might affect ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>6706</td>\n",
       "      <td>lava</td>\n",
       "      <td>Medan,Indonesia</td>\n",
       "      <td>@YoungHeroesID Lava Blast &amp;amp; Power Red #Pan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>7470</td>\n",
       "      <td>obliteration</td>\n",
       "      <td>Merica!</td>\n",
       "      <td>@Eganator2000 There aren't many Obliteration s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>7691</td>\n",
       "      <td>panic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just had a panic attack bc I don't have enough...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1242</td>\n",
       "      <td>blood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Omron HEM-712C Automatic Blood Pressure Monito...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>10862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Officials say a quarantine is in place at an A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>10409</td>\n",
       "      <td>whirlwind</td>\n",
       "      <td>Stamford &amp; Cork (&amp; Shropshire)</td>\n",
       "      <td>I moved to England five years ago today. What ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6090 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       keyword                        location  \\\n",
       "4996   7128      military                           Texas   \n",
       "3263   4688      engulfed                             NaN   \n",
       "4907   6984      massacre              Cottonwood Arizona   \n",
       "2855   4103       drought                     Spokane, WA   \n",
       "4716   6706          lava                 Medan,Indonesia   \n",
       "...     ...           ...                             ...   \n",
       "5226   7470  obliteration                         Merica!   \n",
       "5390   7691         panic                             NaN   \n",
       "860    1242         blood                             NaN   \n",
       "7603  10862           NaN                             NaN   \n",
       "7270  10409     whirlwind  Stamford & Cork (& Shropshire)   \n",
       "\n",
       "                                                   text  target  \n",
       "4996  Courageous and honest analysis of need to use ...       1  \n",
       "3263  @ZachZaidman @670TheScore wld b a shame if tha...       0  \n",
       "4907  Tell @BarackObama to rescind medals of 'honor'...       1  \n",
       "2855  Worried about how the CA drought might affect ...       1  \n",
       "4716  @YoungHeroesID Lava Blast &amp; Power Red #Pan...       0  \n",
       "...                                                 ...     ...  \n",
       "5226  @Eganator2000 There aren't many Obliteration s...       0  \n",
       "5390  just had a panic attack bc I don't have enough...       0  \n",
       "860   Omron HEM-712C Automatic Blood Pressure Monito...       0  \n",
       "7603  Officials say a quarantine is in place at an A...       1  \n",
       "7270  I moved to England five years ago today. What ...       1  \n",
       "\n",
       "[6090 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### testing set ####\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  \n",
       "0                    Just happened a terrible car crash  \n",
       "1     Heard about #earthquake is different cities, s...  \n",
       "2     there is a forest fire at spot pond, geese are...  \n",
       "3              Apocalypse lighting. #Spokane #wildfires  \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan  \n",
       "...                                                 ...  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  \n",
       "3259  Storm in RI worse than last hurricane. My city...  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...  \n",
       "\n",
       "[3263 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### sample_submission ####\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       0\n",
       "1         2       0\n",
       "2         3       0\n",
       "3         9       0\n",
       "4        11       0\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       0\n",
       "3260  10868       0\n",
       "3261  10874       0\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('#### training set ####')\n",
    "display(train_df)\n",
    "print('\\n#### testing set ####')\n",
    "display(test_df)\n",
    "print('\\n#### sample_submission ####')\n",
    "display(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98772a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTweetDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        sentences = dataframe.text.values.tolist()\n",
    "        sentences = [self._preprocess(sentence) for sentence in sentences]\n",
    "        self.sentences = sentences\n",
    "        self.tokenized_sentences = [tokenizer(sentence, padding='max_length',\n",
    "                                max_length=70,\n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\")\n",
    "                      for sentence in sentences]\n",
    "\n",
    "        if 'target' in dataframe:\n",
    "            classes = dataframe.target.values.tolist()\n",
    "            self.labels = classes\n",
    "    def _preprocess(self, sentence):\n",
    "        sentence = self._remove_amp(sentence)\n",
    "        sentence = self._remove_links(sentence)\n",
    "        sentence = self._remove_hashes(sentence)\n",
    "        sentence = self._remove_retweets(sentence)\n",
    "        sentence = self._remove_mentions(sentence)\n",
    "        sentence = self._remove_multiple_spaces(sentence)\n",
    "#         sentence = self._lowercase(sentence)\n",
    "        sentence = self._remove_punctuation(sentence)\n",
    "        tokens = self._tokenize(sentence)\n",
    "#         tokens = self._stopword_filtering(tokens)\n",
    "#         tokens = self._lemmatization(tokens)\n",
    "        sentence = self._stitch_text_tokens_together(tokens)\n",
    "        return sentence.strip()\n",
    "    def _remove_amp(self, sentence):\n",
    "        return sentence.replace(\"&amp;\", \" \")\n",
    "    \n",
    "    def _remove_links(self, sentence):\n",
    "        return re.sub(r'https?:\\/\\/[^\\s\\n\\r]+', ' ', sentence)\n",
    "    \n",
    "    def _remove_hashes(self, sentence):\n",
    "        return re.sub(r'#', ' ', sentence)\n",
    "    \n",
    "    def _remove_retweets(self, sentence):\n",
    "        return re.sub(r'^RT[\\s]+', ' ', sentence)\n",
    "\n",
    "    def _remove_mentions(self, sentence):\n",
    "        return re.sub(r'(@.*?)[\\s]', ' ', sentence)\n",
    "    \n",
    "    def _remove_multiple_spaces(self, sentence):\n",
    "        return re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    def _lowercase(self, sentence):\n",
    "        return sentence.lower()\n",
    "    \n",
    "    def _remove_punctuation(self, sentence):\n",
    "        return ''.join(character for character in sentence if character not in string.punctuation)\n",
    "    \n",
    "    def _tokenize(self, sentence):\n",
    "        return nltk.word_tokenize(sentence, language=\"english\")\n",
    "    \n",
    "    def _stopword_filtering(self, tokens):\n",
    "        stop_words = nltk.corpus.stopwords.words('english')\n",
    "        return [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    def _lemmatization(self, tokens):\n",
    "        wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "        return [wordnet_lemmatizer.lemmatize(token, pos='v') for token in tokens]\n",
    "\n",
    "    def _stemming(self, tokens):\n",
    "        porter = nltk.stem.porter.PorterStemmer()\n",
    "        return [porter.stem(token) for token in tokens]\n",
    "\n",
    "    def _stitch_text_tokens_together(self, text_tokens):\n",
    "        return \" \".join(text_tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.tokenized_sentences[idx]\n",
    "        label = -1\n",
    "        if hasattr(self, 'labels'):\n",
    "            label = self.labels[idx]\n",
    "        return sentence, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "989d82e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertBasedTweetClassifier(nn.Module):\n",
    "    def __init__(self, bert_based_model):\n",
    "        super().__init__()\n",
    "        self.bert = bert_based_model\n",
    "        self.dropout1 = nn.Dropout(0.6)\n",
    "        self.linear1 = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        bert_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)[0][:, 0] #self.bert(...)[0] -> (batch_size, seq_len, hidden_state_size)\n",
    "        x = self.dropout1(bert_out)\n",
    "        x = self.linear1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "805bb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_bert(model, train_dataloader, val_dataloader, learning_rate, epochs):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    loss_func = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.to(device)\n",
    "    loss_func = loss_func.to(device)\n",
    "    best_val_loss = sys.float_info.max\n",
    "    no_promotion_count = 0\n",
    "    for epoch in range(epochs):\n",
    "        count_for_successfully_pred_in_training_set = 0\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            attention_mask = train_input['attention_mask'].to(device)\n",
    "            input_ids = train_input['input_ids'].squeeze(1).to(device) #from (batch_size,1,150) -> (batch_size, 150)\n",
    "            train_label = train_label.to(device)\n",
    "            output = model(input_ids, attention_mask)\n",
    "            loss = loss_func(output, train_label.float().unsqueeze(1))\n",
    "            total_train_loss += loss.item()\n",
    "            acc = ((output >= 0.5).int() == train_label.unsqueeze(1)).sum().item()\n",
    "            count_for_successfully_pred_in_training_set += acc\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            count_for_successfully_pred_in_val_set = 0\n",
    "            total_val_loss = 0\n",
    "            model.eval()\n",
    "            for val_input, val_label in tqdm(val_dataloader):\n",
    "                attention_mask = val_input['attention_mask'].to(device)\n",
    "                input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
    "                val_label = val_label.to(device)\n",
    "                output = model(input_ids, attention_mask)\n",
    "                loss = loss_func(output, val_label.float().unsqueeze(1))\n",
    "                total_val_loss += loss.item()\n",
    "                acc = ((output >= 0.5).int() == val_label.unsqueeze(1)).sum().item()\n",
    "                count_for_successfully_pred_in_val_set += acc\n",
    "\n",
    "            avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "            avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "            avg_train_acc = count_for_successfully_pred_in_training_set / len(train_dataloader.dataset)\n",
    "            avg_val_acc = count_for_successfully_pred_in_val_set / len(val_dataloader.dataset)\n",
    "            print(f'Epochs: {epoch + 1} '\n",
    "                  f'| Train Loss: {avg_train_loss: .4f} '\n",
    "                  f'| Train Accuracy: {avg_train_acc: .4f} '\n",
    "                  f'| Val Loss: {avg_val_loss: .4f} '\n",
    "                  f'| Val Accuracy: {avg_val_acc: .4f}')\n",
    "            \n",
    "            if best_val_loss > avg_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model, f\"best_bert_model.pt\")\n",
    "                print(\"Saved model\")\n",
    "                no_promotion_count = 0\n",
    "            else:\n",
    "                no_promotion_count += 1\n",
    "                \n",
    "            if no_promotion_count >= 10:\n",
    "                print(\"Early stopping\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c657ce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL_TYPE = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_TYPE)\n",
    "bert_based_model = AutoModel.from_pretrained(BERT_MODEL_TYPE)\n",
    "bert_based_tweet_classifier = BertBasedTweetClassifier(bert_based_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37bd9c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(BertTweetDataset(train_df, tokenizer), batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(BertTweetDataset(val_df, tokenizer), batch_size=16)\n",
    "test_dataloader = DataLoader(BertTweetDataset(test_df, tokenizer), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecf28288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After text preprocessing:\n",
      "Max length of tokens in one sentence= 53 | Average length of tokens in one sentence= 19.514773473407747\n"
     ]
    }
   ],
   "source": [
    "# Check length\n",
    "max_num_of_tokens = 0\n",
    "keep_sentence = ''\n",
    "count = 0\n",
    "loader = val_dataloader\n",
    "for sentence in loader.dataset.sentences:\n",
    "    num_of_tokens = tokenizer(sentence, return_tensors=\"pt\")['input_ids'].shape[1]\n",
    "    count += num_of_tokens\n",
    "    keep_sentence = sentence if max_num_of_tokens < num_of_tokens else keep_sentence\n",
    "    max_num_of_tokens = num_of_tokens if max_num_of_tokens < num_of_tokens else max_num_of_tokens\n",
    "print(f'After text preprocessing:\\nMax length of tokens in one sentence= {max_num_of_tokens} | Average length of tokens in one sentence= {count / len(loader.dataset.sentences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0d54c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [32:56<00:00,  5.19s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [02:35<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.4734 | Train Accuracy:  0.7749 | Val Loss:  0.3771 | Val Accuracy:  0.8431\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [32:33<00:00,  5.13s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [02:28<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.3625 | Train Accuracy:  0.8514 | Val Loss:  0.3780 | Val Accuracy:  0.8372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [32:27<00:00,  5.11s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [02:33<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.3068 | Train Accuracy:  0.8762 | Val Loss:  0.4093 | Val Accuracy:  0.8326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [32:27<00:00,  5.11s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [02:33<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.2446 | Train Accuracy:  0.9018 | Val Loss:  0.5105 | Val Accuracy:  0.8424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [32:33<00:00,  5.13s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [02:28<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.1900 | Train Accuracy:  0.9241 | Val Loss:  0.6361 | Val Accuracy:  0.8070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [32:14<00:00,  5.08s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [02:28<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.1541 | Train Accuracy:  0.9399 | Val Loss:  0.6199 | Val Accuracy:  0.8214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [31:59<00:00,  5.04s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [02:35<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.1210 | Train Accuracy:  0.9535 | Val Loss:  0.6371 | Val Accuracy:  0.8194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [31:48<00:00,  5.01s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [02:31<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss:  0.1068 | Train Accuracy:  0.9603 | Val Loss:  0.7290 | Val Accuracy:  0.8083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [31:56<00:00,  5.03s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [02:30<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss:  0.0809 | Train Accuracy:  0.9673 | Val Loss:  0.8699 | Val Accuracy:  0.8070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [31:53<00:00,  5.02s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [02:30<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss:  0.0797 | Train Accuracy:  0.9693 | Val Loss:  0.8843 | Val Accuracy:  0.8135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [31:56<00:00,  5.03s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [02:30<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 11 | Train Loss:  0.0639 | Train Accuracy:  0.9736 | Val Loss:  0.8605 | Val Accuracy:  0.8102\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "epochs = 16\n",
    "train_with_bert(bert_based_tweet_classifier, train_dataloader, val_dataloader, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6543d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disaster_predictions_for_bert(model, loader):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    results_predictions = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data_input, _ in tqdm(loader):\n",
    "            attention_mask = data_input['attention_mask'].to(device)\n",
    "            input_ids = data_input['input_ids'].squeeze(1).to(device)\n",
    "            output = model(input_ids, attention_mask)\n",
    "            output = (output > 0.5).int()\n",
    "            results_predictions.append(output)\n",
    "    return torch.cat(results_predictions, 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b0ac0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 204/204 [05:36<00:00,  1.65s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1\n",
       "5  12       1\n",
       "6  21       0\n",
       "7  22       0\n",
       "8  27       0\n",
       "9  29       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_model = torch.load(\"best_bert_model.pt\")\n",
    "test_data_prediction = disaster_predictions_for_bert(predict_model, test_dataloader)\n",
    "test_data_prediction = test_data_prediction.reshape(-1,)\n",
    "sample_submission[\"target\"] = test_data_prediction\n",
    "display(sample_submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8181339",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission_bert5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107298d7",
   "metadata": {},
   "source": [
    "Below, we test for our scraped dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3e21140",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_df = pd.read_csv(\"scrape_test.csv\", encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4cc62754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 128/128 [03:32<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = DataLoader(BertTweetDataset(test2_df, tokenizer), batch_size=16)\n",
    "predict_model = torch.load(\"best_bert_model.pt\")\n",
    "test_data_prediction = disaster_predictions_for_bert(predict_model, test_dataloader)\n",
    "test_data_prediction = test_data_prediction.reshape(-1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a668cd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6f6f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test2_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0c81ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_arr = y_true.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76461680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e239e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1027,  279],\n",
       "       [ 126,  605]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true_arr, test_data_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f49674b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
